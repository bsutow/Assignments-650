{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and define common helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import json\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import pyarrow as pa\n",
    "from pyarrow.json import read_json\n",
    "import pyarrow.parquet as pq\n",
    "import fastavro\n",
    "import pygeohash\n",
    "import snappy\n",
    "import jsonschema\n",
    "from jsonschema.exceptions import ValidationError\n",
    "\n",
    "\n",
    "endpoint_url='https://storage.budsc.midwest-datascience.com'\n",
    "\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "schema_dir = current_dir.joinpath('schemas')\n",
    "results_dir = current_dir.joinpath('results')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def read_jsonl_data():\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=True,\n",
    "        client_kwargs={\n",
    "            'endpoint_url': endpoint_url\n",
    "        }\n",
    "    )\n",
    "    src_data_path = 'data/processed/openflights/routes.jsonl.gz'\n",
    "    with s3.open(src_data_path, 'rb') as f_gz:\n",
    "        with gzip.open(f_gz, 'rb') as f:\n",
    "            records = [json.loads(line) for line in f.readlines()]\n",
    "        \n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the records from https://storage.budsc.midwest-datascience.com/data/processed/openflights/routes.jsonl.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"airline\": {\n",
      "        \"airline_id\": 410,\n",
      "        \"name\": \"Aerocondor\",\n",
      "        \"alias\": \"ANA All Nippon Airways\",\n",
      "        \"iata\": \"2B\",\n",
      "        \"icao\": \"ARD\",\n",
      "        \"callsign\": \"AEROCONDOR\",\n",
      "        \"country\": \"Portugal\",\n",
      "        \"active\": true\n",
      "    },\n",
      "    \"src_airport\": {\n",
      "        \"airport_id\": 2965,\n",
      "        \"name\": \"Sochi International Airport\",\n",
      "        \"city\": \"Sochi\",\n",
      "        \"country\": \"Russia\",\n",
      "        \"iata\": \"AER\",\n",
      "        \"icao\": \"URSS\",\n",
      "        \"latitude\": 43.449902,\n",
      "        \"longitude\": 39.9566,\n",
      "        \"altitude\": 89,\n",
      "        \"timezone\": 3.0,\n",
      "        \"dst\": \"N\",\n",
      "        \"tz_id\": \"Europe/Moscow\",\n",
      "        \"type\": \"airport\",\n",
      "        \"source\": \"OurAirports\"\n",
      "    },\n",
      "    \"dst_airport\": {\n",
      "        \"airport_id\": 2990,\n",
      "        \"name\": \"Kazan International Airport\",\n",
      "        \"city\": \"Kazan\",\n",
      "        \"country\": \"Russia\",\n",
      "        \"iata\": \"KZN\",\n",
      "        \"icao\": \"UWKD\",\n",
      "        \"latitude\": 55.606201171875,\n",
      "        \"longitude\": 49.278701782227,\n",
      "        \"altitude\": 411,\n",
      "        \"timezone\": 3.0,\n",
      "        \"dst\": \"N\",\n",
      "        \"tz_id\": \"Europe/Moscow\",\n",
      "        \"type\": \"airport\",\n",
      "        \"source\": \"OurAirports\"\n",
      "    },\n",
      "    \"codeshare\": false,\n",
      "    \"equipment\": [\n",
      "        \"CR2\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "records = read_jsonl_data()\n",
    "print(json.dumps(records[0], sort_keys=False, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.a JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'$schema': 'http://json-schema.org/draft-04/schema#', 'type': 'object', 'properties': {'airline': {'type': 'object', 'properties': {'airline_id': {'type': 'integer'}, 'name': {'type': 'string'}, 'alias': {'type': 'string'}, 'iata': {'type': 'string'}, 'icao': {'type': 'string'}, 'callsign': {'type': 'string'}, 'country': {'type': 'string'}, 'active': {'type': 'boolean'}}, 'required': ['airline_id', 'name', 'alias', 'iata', 'icao', 'callsign', 'country', 'active']}, 'src_airport': {'type': 'object', 'properties': {'airport_id': {'type': 'integer'}, 'name': {'type': 'string'}, 'city': {'type': 'string'}, 'country': {'type': 'string'}, 'iata': {'type': 'string'}, 'icao': {'type': 'string'}, 'latitude': {'type': 'number'}, 'longitude': {'type': 'number'}, 'altitude': {'type': 'integer'}, 'timezone': {'type': 'number'}, 'dst': {'type': 'string'}, 'tz_id': {'type': 'string'}, 'type': {'type': 'string'}, 'source': {'type': 'string'}}, 'required': ['airport_id', 'name', 'city', 'country', 'iata', 'icao', 'latitude', 'longitude', 'altitude', 'timezone', 'dst', 'tz_id', 'type', 'source']}, 'dst_airport': {'type': 'object', 'properties': {'airport_id': {'type': 'integer'}, 'name': {'type': 'string'}, 'city': {'type': 'string'}, 'country': {'type': 'string'}, 'iata': {'type': 'string'}, 'icao': {'type': 'string'}, 'latitude': {'type': 'number'}, 'longitude': {'type': 'number'}, 'altitude': {'type': 'integer'}, 'timezone': {'type': 'number'}, 'dst': {'type': 'string'}, 'tz_id': {'type': 'string'}, 'type': {'type': 'string'}, 'source': {'type': 'string'}}, 'required': ['airport_id', 'name', 'city', 'country', 'iata', 'icao', 'latitude', 'longitude', 'altitude', 'timezone', 'dst', 'tz_id', 'type', 'source']}, 'codeshare': {'type': 'boolean'}, 'equipment': {'type': 'array', 'items': [{'type': 'string'}]}}, 'required': ['airline', 'src_airport', 'dst_airport', 'codeshare', 'equipment']}\n",
      "None is not of type 'object'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"None is not of type 'object'\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_jsonl_data(records):\n",
    "    schema_path = schema_dir.joinpath('routes-schema.json')\n",
    "    with open(schema_path) as f:\n",
    "        _schema = json.load(f)\n",
    "\n",
    "    print(_schema)\n",
    "\n",
    "    validation_csv_path = results_dir.joinpath('validation-results.csv')\n",
    "    with open(validation_csv_path, 'w') as f:\n",
    "        for i, record in enumerate(records):\n",
    "            try:\n",
    "                ## TODO: Validate record\n",
    "                jsonschema.validate(record, _schema)\n",
    "                ##pass\n",
    "            except ValidationError as e:\n",
    "                ## Print message if invalid record\n",
    "                detail = e.message\n",
    "                print(detail)\n",
    "                f.write(str(detail))\n",
    "                return detail\n",
    "\n",
    "validate_jsonl_data(records)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.b Avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastavro import writer, parse_schema\n",
    "from fastavro.schema import load_schema\n",
    "def create_avro_dataset(records):\n",
    "    schema_path = schema_dir.joinpath('routes.avsc')\n",
    "    print(schema_path)\n",
    "    data_path = results_dir.joinpath('routes.avro')\n",
    "    print(data_path)\n",
    "    ## TODO: Use fastavro to create Avro dataset\n",
    "    parsed_schema = load_schema(schema_path)\n",
    "    with open(data_path, 'wb') as out:\n",
    "        writer(out, parsed_schema, records)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/dsc650/dsc650/assignments/assignment03/schemas/routes.avsc\n",
      "/home/jovyan/dsc650/dsc650/assignments/assignment03/results/routes.avro\n"
     ]
    }
   ],
   "source": [
    "create_avro_dataset(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.c Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_parquet_dataset():\n",
    "    src_data_path = 'data/processed/openflights/routes.jsonl.gz'\n",
    "    parquet_output_path = results_dir.joinpath('routes.parquet')\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=True,\n",
    "        client_kwargs={\n",
    "            'endpoint_url': endpoint_url\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    with s3.open(src_data_path, 'rb') as f_gz:\n",
    "        with gzip.open(f_gz, 'rb') as f:\n",
    "            #pass\n",
    "            ## TODO: Use Apache Arrow to create Parquet table and save the dataset\n",
    "            records= [json.loads(line) for line in f.readlines()]\n",
    "            df= pd.DataFrame(records)\n",
    "            table= pa.Table.from_pandas(df)\n",
    "            pq.write_table(table, parquet_output_path)\n",
    "            return parquet_output_path\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jovyan/dsc650/dsc650/assignments/assignment03/results/routes.parquet')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_parquet_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.d Protocol Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "airport",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-13048569a57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mcreate_protobuf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-13048569a57a>\u001b[0m in \u001b[0;36mcreate_protobuf_dataset\u001b[0;34m(records)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_airport_to_proto_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src_airport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0msrc_airport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_airport_to_proto_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'src_aiport'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mroute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mairport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_airport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_airport_to_proto_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dst_airport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: airport"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, os.path.abspath('routes_pb2'))\n",
    "\n",
    "import routes_pb2\n",
    "\n",
    "def _airport_to_proto_obj(airport):\n",
    "    obj = routes_pb2.Airport()\n",
    "    if airport is None:\n",
    "        return None\n",
    "    if airport.get('airport_id') is None:\n",
    "        return None\n",
    "\n",
    "    obj.airport_id = airport.get('airport_id')\n",
    "    if airport.get('name'):\n",
    "        obj.name = airport.get('name')\n",
    "    if airport.get('city'):\n",
    "        obj.city = airport.get('city')\n",
    "    if airport.get('iata'):\n",
    "        obj.iata = airport.get('iata')\n",
    "    if airport.get('icao'):\n",
    "        obj.icao = airport.get('icao')\n",
    "    if airport.get('altitude'):\n",
    "        obj.altitude = airport.get('altitude')\n",
    "    if airport.get('timezone'):\n",
    "        obj.timezone = airport.get('timezone')\n",
    "    if airport.get('dst'):\n",
    "        obj.dst = airport.get('dst')\n",
    "    if airport.get('tz_id'):\n",
    "        obj.tz_id = airport.get('tz_id')\n",
    "    if airport.get('type'):\n",
    "        obj.type = airport.get('type')\n",
    "    if airport.get('source'):\n",
    "        obj.source = airport.get('source')\n",
    "\n",
    "    obj.latitude = airport.get('latitude')\n",
    "    obj.longitude = airport.get('longitude')\n",
    "\n",
    "    return obj\n",
    "\n",
    "def _airline_to_proto_obj(airline):\n",
    "    obj = routes_pb2.Airline()\n",
    "    if not airline.get('name'):\n",
    "        return None\n",
    "    if not airline.get('airline_id'):\n",
    "        return None\n",
    "    obj.airline_id = airline.get('airline_id')\n",
    "    obj.name = airline.get('name')\n",
    "    if airline.get('alias'):\n",
    "        obj.alias = airline.get('alias')\n",
    "    ## TODO\n",
    "    return obj\n",
    "\n",
    "def create_protobuf_dataset(records):\n",
    "    routes = routes_pb2.Routes()\n",
    "    for record in records:\n",
    "        route = routes_pb2.Route()\n",
    "        airline = _airline_to_proto_obj(record.get('airline', {}))\n",
    "        if airline:\n",
    "            route.airline.CopyFrom(airline)\n",
    "        \n",
    "            \n",
    "            \n",
    "        if _airport_to_proto_obj(record['src_airport']) is not None:\n",
    "            src_airport = _airport_to_proto_obj(record.get('src_aiport', {}))\n",
    "            route.airport.CopyFrom(src_airport)\n",
    "\n",
    "        if _airport_to_proto_obj(record['dst_airport']) is not None:\n",
    "            dst_airport = _airport_to_proto_obj(record.get('dst_aiport', {}))\n",
    "            route.airport.CopyFrom(dst_airport)\n",
    "\n",
    "        \n",
    "        routes.route.append(route)\n",
    "        \n",
    "    data_path = results_dir.joinpath('routes.pb')\n",
    "    with open(data_path, 'wb') as f:\n",
    "        f.write(routes.SerializeToString())\n",
    "        \n",
    "    compressed_path = results_dir.joinpath('routes.pb.snappy')\n",
    "    \n",
    "        \n",
    "create_protobuf_dataset(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snappy\n",
    "\n",
    "def snappy_compress(routes):\n",
    "        path_to_store = path+'.snappy'\n",
    "\n",
    "        with open(path, 'wb') as in_file:\n",
    "          with open(path_to_store, 'w') as out_file:\n",
    "            snappy.stream_compress(in_file, out_file)\n",
    "            out_file.close()\n",
    "            in_file.close()\n",
    "\n",
    "        return path_to_store\n",
    "\n",
    "snappy_compress('testfile.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.a Simple Geohash Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hash_dirs(records):\n",
    "    geoindex_dir = results_dir.joinpath('geoindex')\n",
    "    geoindex_dir.mkdir(exist_ok=True, parents=True)\n",
    "    hashes = []\n",
    "    ## TODO: Create hash index\n",
    "            \n",
    "create_hash_dirs(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hash_dirs(records):\n",
    "    geoindex_dir = results_dir.joinpath('geoindex')\n",
    "    geoindex_dir.mkdir(exist_ok=True, parents=True)\n",
    "    hashes = []\n",
    "    for record in records:\n",
    "        src_airport = record.get('src_airport', {})\n",
    "        if src_airport:\n",
    "            latitude = src_airport.get('latitude')\n",
    "            longitude = src_airport.get('longitude')\n",
    "            if latitude and longitude:\n",
    "                pygeohash.encode(latitude, longitude)\n",
    "    hashes.sort()\n",
    "    three_letter = sorted(list(set([entry[:3] for entry in hashes])))\n",
    "    hash_index = {value: [] for value in three_letter}\n",
    "    for record in records:\n",
    "        geohash = record.get('geohash')\n",
    "        if geohash:\n",
    "            hash_index[geohash[:3]].append(record)\n",
    "    for key, values in hash_index.items():\n",
    "        output_dir = geoindex_dir.joinpath(str(key[:1])).joinpath(str(key[:2]))\n",
    "        output_dir.mkdir(exist_ok=True, parents=True)\n",
    "        output_path = output_dir.joinpath('{}.jsonl.gz'.format(key))\n",
    "        with gzip.open(output_path, 'w') as f:\n",
    "            json_output = '\\n'.join([json.dumps(value) for value in values])\n",
    "            f.write(json_output.encode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_hash_dirs(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.b Simple Search Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meters From Location: 625.441\n",
      "LAT: 41.1499988\n",
      "LONG: -95.91779\n",
      "{'Airport Name': 'Eppley Airfield', 'Latitude': 41.3032, 'Longitude': -95.89409599999999, 'Distance(m)': 123.264}\n",
      "{'Airport Name': 'Lincoln Airport', 'Latitude': 40.85100173950195, 'Longitude': -96.75920104980469, 'Distance(m)': 123.264}\n"
     ]
    }
   ],
   "source": [
    "def airport_search(latitude, longitude, distm):\n",
    "    ## TODO: Create simple search to return nearest airport\n",
    "    distm = distm / 1000\n",
    "    srcgeoval = pygeohash.encode(latitude, longitude, precision=3)\n",
    "    AirportDistances = []\n",
    "    airrecord = []\n",
    "    \n",
    "    for record in records:\n",
    "        for key, value in record.items():\n",
    "            if key == 'src_airport' and value is not None:\n",
    "                if value not in airrecord:\n",
    "                    airrecord.append(value)\n",
    "\n",
    "    \n",
    "    for record in airrecord:\n",
    "        dstname = record['name']\n",
    "        dstlat = record['latitude']\n",
    "        dstlong = record['longitude']\n",
    "        geohval = pygeohash.encode(dstlat, dstlong, precision=3)\n",
    "        distm_dstgeo1 = pygeohash.geohash_approximate_distance(srcgeoval, geohval) / 1000\n",
    "        airport_dist = {\n",
    "            \"Airport Name\": dstname,\n",
    "            \"Latitude\": dstlat,\n",
    "            \"Longitude\": dstlong,\n",
    "            \"Distance(m)\": distm_dstgeo1\n",
    "        }\n",
    "        AirportDistances.append(airport_dist)\n",
    "\n",
    "    DistList = list(unique_everseen(AirportDistances))\n",
    "    print(\"Meters From Location: \"+str(distm))\n",
    "    print(\"LAT: \"+str(latitude))\n",
    "    print(\"LONG: \"+str(longitude))\n",
    "    for i in range(len(DistList)):\n",
    "        for a, b in DistList[i].items():\n",
    "            if a == 'Distance(m)':\n",
    "                if b < distm: \n",
    "                    print(DistList[i])\n",
    "    ##pass\n",
    "\n",
    "distm = 625441\n",
    "airport_search(41.1499988, -95.91779, distm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
